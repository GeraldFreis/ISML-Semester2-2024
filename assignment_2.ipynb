{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", low_memory=False)\n",
    "test_df = pd.read_csv(\"test.csv\", low_memory=False)\n",
    "train_df['0.00'] = train_df['0.00'].replace([0.0], [-1.0])\n",
    "test_df['1.00'] = test_df['1.00'].replace([0.0], [-1.0])\n",
    "\n",
    "val_df = train_df[4000::1]\n",
    "train_df = train_df[0:4000:1]\n",
    "\n",
    "train_x = train_df.drop(columns=['0.00'])\n",
    "train_y = train_df['0.00']\n",
    "\n",
    "val_x = val_df.drop(columns=['0.00'])\n",
    "val_y = val_df['0.00']\n",
    "\n",
    "test_x = test_df.drop(columns=['1.00'])\n",
    "test_y = test_df['1.00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Primal Form soft margin SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cv\n",
    "def svm_train_primal(data_train, label_train, regularisation_constant):\n",
    "    \"\"\"Training the w and b parameters for the soft margin SVM in primal Form\"\"\"\n",
    "   \n",
    "\n",
    "    # defining variables\n",
    "    n_samples, n_features = data_train.shape \n",
    "    w = cv.Variable(n_features)\n",
    "    b = cv.Variable()\n",
    "    x_i = cv.Variable(n_samples)\n",
    "\n",
    "    # minimising the objective function for the soft margin SVM \n",
    "    objective_function = cv.Minimize(0.5 * cv.norm(w, 2) ** 2 + regularisation_constant * cv.sum(x_i))\n",
    "\n",
    "    # setting the constraints formulas\n",
    "    constraints = [label_train[i] * (data_train[i] @ w + b) >= 1 - x_i[i] for i in range(n_samples)]\n",
    "    constraints += [x_i >= 0] # making sure all alpha's are greater than zero\n",
    "\n",
    "    # optimising the problem according to the constraints\n",
    "    prob = cv.Problem(objective_function, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    return w.value, b.value, x_i\n",
    "\n",
    "def svm_predict_primal ( data_test , label_test , svm_model ):\n",
    "    return np.sign(data_test @ svm_model[0] + svm_model[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training SVM model with primal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm_train_primal(train_x.to_numpy(), train_y.to_numpy(), 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting accuracies for primal svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions_train = svm_predict_primal(train_x.to_numpy(), train_y.to_numpy(), svm_model)\n",
    "svm_predictions_test = svm_predict_primal(test_x.to_numpy(), test_y.to_numpy(), svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 98.45%\n",
      "Test Accuracy: 96.86%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = np.mean(svm_predictions_train == train_y.to_numpy()) * 100\n",
    "test_accuracy = np.mean(svm_predictions_test == test_y.to_numpy()) * 100\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing W and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of W across dimensions: -0.16\n",
      "b: 2.980545994257868\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of W across dimensions: {:.2f}\\nb: {}\".format(svm_model[0].sum(), svm_model[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the support vectors for the Prime form soft margin SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you take all predictions within some tolerance limit (1e-5) of the hyperplane\n",
    "predictions_for_train = train_y.to_numpy() * (train_x.to_numpy().dot(svm_model[0]) + svm_model[1]) \n",
    "\n",
    "support_vector_indexs = np.where(predictions_for_train <= 1 + 1e-5)\n",
    "support_vectors = train_x.to_numpy()[support_vector_indexs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315, 200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing soft margin SVM in dual form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "\n",
    "def svm_train_dual ( data_train , label_train , regularisation_para_C ):\n",
    "    # initialising variables\n",
    "    n, m = data_train.shape\n",
    "    a = cvx.Variable(n)\n",
    "    \n",
    "    # setting the linear kernel\n",
    "    sum_function = cvx.sum_squares(cvx.matmul (cvx.multiply(a, label_train), data_train ) ) \n",
    "    # setting the objective function as required\n",
    "    # objective_function = cvx.Minimize(-cvx.sum(a) + 0.5 * cvx.sum ( cvx.multiply ( cvx.multiply( a, label_train ) , k @ cvx.multiply( a, label_train ) ) ) )\n",
    "    # objective_function = cvx.Minimize(0.5 * cvx.sum(cvx.multiply(a, k @ a)) - cvx.sum(a))\n",
    "    objective_function = cvx.Maximize(cvx.sum(a) - 0.5 * sum_function)\n",
    "    # objective_function = cvx.Minimize( 0.5 * cvx.quad_form( cvx.multiply(a, label_train), k) - cvx.sum(a) )\n",
    "\n",
    "    # setting the constraints\n",
    "    constraints = [ a <= regularisation_para_C / n, a >= 0, cvx.sum(cvx.multiply(a, label_train)) == 0]\n",
    "\n",
    "    # maximising the problem in regards to the constraints\n",
    "    problem = cvx.Problem(objective_function, constraints)\n",
    "    problem.solve()\n",
    "\n",
    "   \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting w and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = svm_train_dual(train_x.to_numpy(), train_y.to_numpy(), regularisation_para_C=100)\n",
    "# now calculating w and b\n",
    "w = np.sum((a.value * train_y.to_numpy())[:,None] * train_x.to_numpy(), axis = 0)\n",
    "\n",
    "def compute_b(X, y, w, alpha, tol=1e-5):\n",
    "    # Find support vectors (where alpha > 0)\n",
    "    support_vector_indices = np.where((a.value > tol) & (a.value < 1/tol))[0]\n",
    "    \n",
    "    # Use the support vectors to compute b (averaging over all support vectors)\n",
    "    b_vals = []\n",
    "    for idx in support_vector_indices:\n",
    "        b_val = y[idx] - np.dot(w, X[idx])\n",
    "        b_vals.append(b_val)\n",
    "    \n",
    "    # Return the average value of b over all support vectors\n",
    "    return np.mean(b_vals)\n",
    "\n",
    "b = compute_b(train_x.to_numpy(), train_y.to_numpy(), w, a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of W across dimensions: -0.26\n",
      "b: 1.75642789079601\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of W across dimensions: {:.2f}\\nb: {}\".format(w.sum(), b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_predictions_train = svm_predict_primal(train_x.to_numpy(), train_y.to_numpy(), [w, b])\n",
    "svm_predictions_test = svm_predict_primal(test_x.to_numpy(), test_y.to_numpy(), [w, b])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding support vectors from the dual problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_support_vectors(data_train, label_train, a, regularisation_parameter, tol=1e-5):\n",
    " \n",
    "    n, m = data_train.shape  # Number of training samples\n",
    "    support_indices = np.where((a.value >= tol) & (a.value < (regularisation_parameter / n) + tol))[0]\n",
    "    \n",
    "    support_vectors = data_train[support_indices]  # Extract support vector points\n",
    "    support_labels = label_train[support_indices]   # Extract the corresponding labels\n",
    "    \n",
    "    return support_indices, support_vectors, support_labels\n",
    "\n",
    "support_ind, support_vec, support_labl =  find_support_vectors(train_x.to_numpy(), train_y.to_numpy(), a, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing C from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00390625\n",
      "0.015625\n",
      "0.0625\n",
      "0.25\n",
      "1\n",
      "4\n",
      "16\n",
      "64\n",
      "256\n",
      "The optimal C is: 0.0009765625 with accuracy: 97.02156034674371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/MLEnv/lib/python3.8/site-packages/cvxpy/problems/problem.py:1407: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimal_c = 2**(-10)\n",
    "optimal_accuracy = 0;\n",
    "c = 2**(-10)\n",
    "c_s = []\n",
    "for i in range (-10, 10, 2):\n",
    "    c_s.append(2**(i))\n",
    "\n",
    "for c in c_s:\n",
    "    print(c)\n",
    "    svm_model = svm_train_dual(train_x.to_numpy(), train_y.to_numpy(), c)\n",
    "\n",
    "    w = np.sum((a.value * train_y.to_numpy())[:,None] * train_x.to_numpy(), axis = 0)\n",
    "    b = compute_b(train_x.to_numpy(), train_y.to_numpy(), w, a)\n",
    "\n",
    "    acc = svm_predict_primal(val_x.to_numpy(), val_y.to_numpy(), [w, b])\n",
    "    acc = np.mean(acc == val_y.to_numpy()) * 100\n",
    "    if(acc > optimal_accuracy):\n",
    "        optimal_accuracy = acc\n",
    "        optimal_c = c\n",
    "    \n",
    "print(\"The optimal C is: {} with accuracy: {}\".format(optimal_c, optimal_accuracy))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting test accuracy with optimal C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of optimal C of 0.0009765625 for Test set: 96.8646%\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm_train_dual(train_x.to_numpy(), train_y.to_numpy(), optimal_c)\n",
    "w = np.sum((a.value * train_y.to_numpy())[:,None] * train_x.to_numpy(), axis = 0)\n",
    "b = compute_b(train_x.to_numpy(), train_y.to_numpy(), w, a)\n",
    "\n",
    "acc = svm_predict_primal(test_x.to_numpy(), test_y.to_numpy(), [w, b])\n",
    "acc = np.mean(acc == test_y.to_numpy()) * 100\n",
    "print(\"Accuracy of optimal C of {} for Test set: {:.4f}%\".format(optimal_c, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using C with Scikit's Linear svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy with optimal C of 0.0009765625:\t96.6644%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/MLEnv/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(tol=1e-5, C=optimal_c)\n",
    "svm.fit(train_x.to_numpy(), train_y.to_numpy())\n",
    "print(\"SVM accuracy with optimal C of {}:\\t{:.4f}%\".format (optimal_c, svm.score(test_x.to_numpy(), test_y.to_numpy()) * 100 ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
